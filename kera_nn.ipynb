{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam as Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_list = np.array(pd.read_csv('train_labels.csv', usecols=['Category']))\n",
    "train_y = [label[0] for label in train_y_list]\n",
    "\n",
    "dict = {}\n",
    "for label in train_y:\n",
    "    if label in dict:\n",
    "        dict[label] = dict[label]+1\n",
    "    else:\n",
    "        dict[label] = 1\n",
    "        \n",
    "labels = dict.keys()\n",
    "num_class = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    # define sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "\n",
    "    # filters detect the patterns on each image\n",
    "    # Some filters detect edges, some circles, some corners and so on.\n",
    "    # The deeper the network is, the more sophisticated the filters become\n",
    "    # A filter can be thought of as a small matrix for which we decide how many rows and columns it has\n",
    "    # Values within the matrix are initialized with random numbers\n",
    "    # Let's say our matrix is 3 x 3\n",
    "    # When this convolutional layer receives input, the filter will slide over each 3 x 3 set of pixels on the input image\n",
    "    # This sliding is referred to as convolve\n",
    "\n",
    "    num_filter = 32  # number of convolution filters to use\n",
    "    num_row = 3  # number of rows in each convolution kernel \n",
    "    num_col = 3  # number of columns in each convolution kernel\n",
    "\n",
    "    depth = 1\n",
    "    width = 30\n",
    "    height = 30\n",
    "\n",
    "    model.add(Conv2D(num_filter, \n",
    "                     kernel_size=(num_row, num_col),\n",
    "                     activation='relu',\n",
    "                     input_shape=(width, height, depth),\n",
    "                     strides=1,  # number units to shift for the next convolve\n",
    "                     padding='same'))\n",
    "\n",
    "    # After each conv layer, it is convention to apply a nonlinear layer (or activation layer) immediately afterward.\n",
    "    # The purpose of this layer is to introduce nonlinearity to a system that basically has just been computing linear operations during the conv layers.\n",
    "    # In the past, nonlinear functions like tanh and sigmoid were used, but researchers found out that ReLU layers work far better because the network is able to train a lot faster without making a significant difference to the accuracy. \n",
    "    # It also helps to alleviate the vanishing gradient problem, which is the issue where the lower layers of the network train very slowly because the gradient decreases exponentially through the layers . \n",
    "    # The ReLU layer applies the function f(x) = max(0, x) to all of the values in the input volume. In basic terms, this layer changes all the negative activations to 0.\n",
    "    # This layer increases the nonlinear properties of the model and the overall network without affecting the receptive fields of the conv layer.\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    # Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the\n",
    "    # mean activation close to 0 and the activation standard deviation close to 1. \n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    \n",
    "    # 1st hidden layer\n",
    "    model.add(Conv2D(num_filter, kernel_size=(num_row, num_col), strides=1, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    # Pool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "    # 2nd hidden layer\n",
    "    model.add(Conv2D(num_filter, kernel_size=(num_row, num_col), strides=1, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    # pool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "    # 3rd hidden layer\n",
    "    model.add(Conv2D(num_filter, kernel_size=(num_row, num_col), strides=1, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    # pool\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    # Fully connected\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "\n",
    "epoch = 1000\n",
    "batch_size = 512\n",
    "model.fit(train_x, train_y, \n",
    "        validation_data=(test_x, test_y),\n",
    "        shuffle=True, \n",
    "        epochs=epoch, \n",
    "        batch_size=batch_size, \n",
    "        verbose=2)\n",
    "\n",
    "model.save_weights('my_model_weights.h5')\n",
    "\n",
    "# Model prediction on testing data\n",
    "best = model.predict(test, batch_size=batch_size)\n",
    "\n",
    "best = np.argmax(best, axis=1) \n",
    "\n",
    "# Remap the indice of one hot encoded labels to its original label:\n",
    "remap = lambda x: mapping[x]\n",
    "best = best.tolist()        \n",
    "best = [remap(indice) for indice in best]\n",
    "\n",
    "# Write to prediction file\n",
    "pred = pd.DataFrame(data=best)\n",
    "pred.index += 1\n",
    "pred.to_csv(\"cnn_KERAS_1000.csv\", sep=',', header=['Label'], index=True, index_label='ID', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
