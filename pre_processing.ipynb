{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract images from npy files\n",
    "\"\"\"\n",
    "train_x = np.load('train_images.npy', encoding='latin1')\n",
    "train_x = np.array([arr[1] for arr in train_x], np.uint8)\n",
    "train_x = np.array([train_x[idx].reshape(100, 100) for idx in range(len(train_x))], np.uint8)\n",
    "train_y = np.array(pd.read_csv('train_labels.csv', usecols=['Category']))\n",
    "\n",
    "test_x = np.load('test_images.npy', encoding='latin1')\n",
    "test_x = np.array([arr[1] for arr in test_x], np.uint8)\n",
    "test_x = np.array([test_x[idx].reshape(100, 100) for idx in range(len(test_x))], np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(img_gray):\n",
    "    \"\"\"\n",
    "    Finding contours for the\n",
    "    given greyscale image\n",
    "\n",
    "    @param\n",
    "        :type np.array img_gray - greyscale version of the image\n",
    "\n",
    "    @return\n",
    "        :rtype np.array - the image\n",
    "        :rtype np.array - contours found for the image\n",
    "\n",
    "    \"\"\"\n",
    "    ret, thresh = cv2.threshold(img_gray, 127, 255, 0)\n",
    "    thresh = thresh.astype('uint8')\n",
    "    image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    return image, contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_noise_by_contours(image, contours):\n",
    "    \"\"\"\n",
    "    Cleaning out the noise from the\n",
    "    image based on the contours found\n",
    "    using find_contours(img_gray)\n",
    "\n",
    "    @param\n",
    "        :type np.array image - image to clean\n",
    "        :type np.arary contours - contours found for the image\n",
    "\n",
    "    @return\n",
    "        :rtpe np.array - cleaned version of the image\n",
    "        \n",
    "    \"\"\"\n",
    "    num_contour = len(contours)\n",
    "    \n",
    "    max_area = 0\n",
    "    max_area_idx = 0\n",
    "    for i in range(0, num_contour):\n",
    "        contour = contours[i]\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_area_idx = i\n",
    "    \n",
    "    for i in range(0, num_contour):\n",
    "        if i != max_area_idx:\n",
    "            cv2.drawContours(image, contours, i, -1, 3)\n",
    "            \n",
    "    plt.imshow(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(cleaned_img):\n",
    "    \"\"\"\n",
    "    Crop the cleaned image to\n",
    "    return just the drawing\n",
    "    in a smaller square of side 30.\n",
    "\n",
    "    @param\n",
    "        :type np.array cleaned_img - cleaned image\n",
    "\n",
    "    @return\n",
    "        :rtype np.array - cropped version of the cleaned image\n",
    "    \"\"\"\n",
    "    sq_side_length = 30\n",
    "    sq_half_side = int(sq_side_length/2)\n",
    "    center_h, center_w = center_of_mass(cleaned_img)\n",
    "    center_h = int(center_h)\n",
    "    center_w = int(center_w)\n",
    "    top_h = center_h - sq_half_side\n",
    "    bottom_h = center_h + sq_half_side\n",
    "    left_w = center_w - sq_half_side\n",
    "    right_w = center_w + sq_half_side\n",
    "    \n",
    "    new_val_bound = check_within_bounds(top_h)\n",
    "    top_h = new_val_bound[0]\n",
    "    bottom_h += new_val_bound[1]\n",
    "    \n",
    "    new_val_bound = check_within_bounds(bottom_h)\n",
    "    bottom_h = new_val_bound[0]\n",
    "    top_h -= new_val_bound[1]\n",
    "    \n",
    "    new_val_bound = check_within_bounds(left_w)\n",
    "    left_w = new_val_bound[0]\n",
    "    right_w += new_val_bound[1]\n",
    "    \n",
    "    new_val_bound = check_within_bounds(right_w)\n",
    "    right_w = new_val_bound[0]\n",
    "    left_w -= new_val_bound[1]\n",
    "    \n",
    "    cropped_img = cleaned_img[top_h: bottom_h, left_w: right_w]\n",
    "    plt.imshow(cropped_img)\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_within_bounds(val_to_check):\n",
    "    \"\"\"\n",
    "    Check if the x or y coordinate is \n",
    "    within the 100x100 bounds of the image\n",
    "    \n",
    "    @param\n",
    "        :type int val_to_check - coordinate value\n",
    "    \n",
    "    @return\n",
    "        :rtype int - new value for the coordinate\n",
    "        :rtype int - magnitude of overflow beyond the boundary\n",
    "        \n",
    "    \"\"\"\n",
    "    if val_to_check < 0:\n",
    "        return 0, 0 - val_to_check\n",
    "    elif val_to_check > 100:\n",
    "        return 100, val_to_check - 100\n",
    "    else:\n",
    "        return val_to_check, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img, angle):\n",
    "    \"\"\"\n",
    "    Rotates the given image \n",
    "    by 'angle' degrees\n",
    "\n",
    "    @param\n",
    "        :type np.array img - image to rotate\n",
    "        :type int angle - angle in degrees to rotate by\n",
    "\n",
    "    @return\n",
    "        :rtype np.array - original image rotated by 'angle' degrees\n",
    "        \n",
    "    \"\"\"\n",
    "    rows, cols = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), angle, 1)\n",
    "    dst = cv2.warpAffine(img, M, (cols,rows))\n",
    "    plt.imshow(dst)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2721e481a8fc43c9902852dc40c6a115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Don't have to run anymore. Train preprocessed data is saved ####\n",
    "\"\"\"\n",
    "Generating train preprocessed images\n",
    "\"\"\"\n",
    "train_processed_images = []\n",
    "train_rotated_images = []\n",
    "train_rotated_labels = []\n",
    "train_count = 0\n",
    "train_vector_dim = 900\n",
    "for train_pic in tqdm(train_x):\n",
    "    train_image, train_contours = find_contours(train_pic)\n",
    "    train_cleaned_img = clean_noise_by_contours(train_image, train_contours)\n",
    "    train_cropped_img = cropImage(train_cleaned_img)\n",
    "    train_processed_images.append(train_cropped_img.reshape(train_vector_dim,))\n",
    "    for j in range(1, 6):\n",
    "        train_rotated_img = rotate(train_cropped_img, 60*j)\n",
    "        train_rotated_images.append(train_rotated_img.reshape(train_vector_dim,))\n",
    "\n",
    "    train_rotated_labels += [train_y[train_count] for k in range(5)]\n",
    "    train_count += 1\n",
    "\n",
    "train_processed_images += train_rotated_images\n",
    "train_processed_images = np.array(train_processed_images)\n",
    "train_np_rotated_labels = np.array(train_rotated_labels)\n",
    "train_processed_labels = np.concatenate((train_y, train_np_rotated_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 900)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd = np.concatenate((train_processed_images, train_processed_labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 901)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(tpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 901)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffled_images = tpd[:, :900].astype('uint8')\n",
    "train_shuffled_labels = tpd[:, 900:901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_shuffled_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = 54284\n",
    "# print(processed_labels[g])\n",
    "# plt.imshow(processed_images[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving the preprocessed images\n",
    "and the updated labels to new files\n",
    "\"\"\"\n",
    "with h5py.File(\"train_preprocessed_shuffled.hdf5\", \"w\") as h:\n",
    "    dset = h.create_dataset(\"train_preprocessed\", data=train_shuffled_images)\n",
    "\n",
    "df = pd.DataFrame(train_shuffled_labels, columns=['Category'])\n",
    "df.to_csv('train_shuffled_labels.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in the saved data\n",
    "\"\"\"\n",
    "g = h5py.File('train_preprocessed_shuffled.hdf5', 'r')\n",
    "train_preprocessed_x = g['train_preprocessed']\n",
    "train_preprocessed_y = np.array(pd.read_csv('train_shuffled_labels.csv', usecols=['Category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['octagon'],\n",
       "       ['pineapple'],\n",
       "       ['empty'],\n",
       "       ['mug'],\n",
       "       ['rabbit'],\n",
       "       ['peanut'],\n",
       "       ['sink'],\n",
       "       ['pool'],\n",
       "       ['empty'],\n",
       "       ['sink']], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88663aad97c04801a596835cc18bd060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Don't have to run anymore. Test preprocessed data is saved ####\n",
    "\"\"\"\n",
    "Generating test preprocessed images\n",
    "\"\"\"\n",
    "test_processed_images = []\n",
    "test_count = 0\n",
    "test_vector_dim = 900\n",
    "for test_pic in tqdm(test_x):\n",
    "    test_image, test_contours = find_contours(test_pic)\n",
    "    test_cleaned_img = clean_noise_by_contours(test_image, test_contours)\n",
    "    test_cropped_img = cropImage(test_cleaned_img)\n",
    "    test_processed_images.append(test_cropped_img.reshape(test_vector_dim,))\n",
    "\n",
    "    test_count += 1\n",
    "\n",
    "test_processed_images = np.array(test_processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image:\n",
    "    def __init__(self, raw):\n",
    "        self.raw = raw\n",
    "        # self.img is a cv2 array\n",
    "        self.img = self.raw.reshape(100, 100)\n",
    "        # grayscaled image\n",
    "        self.grayscaled_img = cv2.cvtColor(self.img, cv2.COLOR_GRAY2BGR)\n",
    "        # resize grayscaled image\n",
    "        self.gray = cv2.resize(self.grayscaled_img, (100, 100))\n",
    "        # grayscaled image after max pooling\n",
    "        self.resized_img = None\n",
    "        \n",
    "    def show(self, img):\n",
    "        plt.imshow(img)\n",
    "\n",
    "    def clean_noise(self):\n",
    "        img = self.gray\n",
    "        ret, threshold = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "        im2, contours, hierarchy = cv2.findContours(threshold, cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_NONE)\n",
    "        self.show(im2)\n",
    "        return contours\n",
    "        \n",
    "                \n",
    "    # A technique to reduce the dimensions of an image by taking the maximum pixel value of a grid. \n",
    "    # This also helps reduce over-fitting and makes the model more generic. \n",
    "    def max_pooling(self, side_len):\n",
    "        slice_x = 100/side_len\n",
    "        slice_y = slice_x\n",
    "        res = np.zeros((slice_x, slice_y))\n",
    "        for i in range(0, slice_x):\n",
    "            for j in range(0, slice_y):\n",
    "                max = 0\n",
    "                for p in range(i*side_len, (i+1)*side_len):\n",
    "                    for q in range(j*side_len, (j+1)*side_len):\n",
    "                        val = self.grayscaled_img[p][q]\n",
    "                        if val>max: \n",
    "                            max = val\n",
    "                res[i][j] = max\n",
    "        self.resized_img = res\n",
    "        return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
